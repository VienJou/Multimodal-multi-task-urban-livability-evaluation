{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dOnHITFCd61k"
   },
   "source": [
    "# Run MMBT Experiments\n",
    "\n",
    "This notebook shows the end-to-end pipeline for fine-tuning pre-trained MMBT model for multimodal (text and image) classification on our dataset.\n",
    "\n",
    "Parts of this pipeline are adapted from the\n",
    "Huggingface `run_mmimdb.py` script to execute the MMBT model. This code can\n",
    "be accessed [here.](https://github.com/huggingface/transformers/blob/8ea412a86faa8e9edeeb6b5c46b08def06aa03ea/examples/research_projects/mm-imdb/run_mmimdb.py#L305)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ” Hugging Face Authentication (Required)\n",
    "\n",
    "**Important**: The dataset requires Hugging Face authentication. Please login before loading the dataset.\n",
    "\n",
    "### Method 1: Using Hugging Face CLI (Recommended)\n",
    "\n",
    "Run the following commands in a terminal before starting Jupyter:\n",
    "\n",
    "```bash\n",
    "# Install huggingface_hub (if not already installed)\n",
    "pip install huggingface_hub\n",
    "\n",
    "# Login to Hugging Face\n",
    "huggingface-cli login\n",
    "```\n",
    "\n",
    "When prompted, enter your Hugging Face token. You can get your token from:\n",
    "- https://huggingface.co/settings/tokens\n",
    "\n",
    "### Method 2: Set Token in Notebook\n",
    "\n",
    "If you cannot use CLI login (e.g., on web platforms), run the cell below to set your token directly.\n",
    "\n",
    "### Method 3: Pass Token Directly in Code\n",
    "\n",
    "If the above methods don't work, you can pass the token directly in the `load_examples` function. Find the `load_examples` function (usually in Cell 8) and modify the `load_dataset` call:\n",
    "\n",
    "**Original code:**\n",
    "```python\n",
    "hf_dataset_dict = load_dataset(\"Vinjou/Multimodal_urban_livability_evaluation_dataset\")\n",
    "```\n",
    "\n",
    "**Modified code (with token):**\n",
    "```python\n",
    "hf_dataset_dict = load_dataset(\"Vinjou/Multimodal_urban_livability_evaluation_dataset\", token=\"your_token_here\")\n",
    "```\n",
    "\n",
    "Replace `\"your_token_here\"` with your actual Hugging Face token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_TOKEN'] = 'your_token_here'  # Replace with your actual token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install huggingface_hub if not already installed\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    import huggingface_hub\n",
    "    print(\"âœ“ huggingface_hub is already installed\")\n",
    "except ImportError:\n",
    "    print(\"Installing huggingface_hub...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"huggingface_hub\"])\n",
    "    print(\"âœ“ huggingface_hub installed successfully\")\n",
    "\n",
    "# Check if already logged in\n",
    "from huggingface_hub import HfFolder\n",
    "token = HfFolder.get_token()\n",
    "\n",
    "if token:\n",
    "    print(\"âœ“ Hugging Face token found. You are already logged in.\")\n",
    "    print(f\"  Token starts with: {token[:10]}...\")\n",
    "else:\n",
    "    print(\"âš ï¸  No Hugging Face token found.\")\n",
    "    print(\"Please login using one of the following methods:\")\n",
    "    print(\"  1. Run in terminal: huggingface-cli login\")\n",
    "    print(\"  2. Or set token below:\")\n",
    "    print()\n",
    "    print(\"# Uncomment and set your token:\")\n",
    "    print(\"# import os\")\n",
    "    print(\"# os.environ['HF_TOKEN'] = 'your_token_here'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix Jupyter widgets warning (optional - this warning doesn't affect code execution)\n",
    "# The error about '@jupyter-widgets/controls' is a frontend display issue, not a code error.\n",
    "# Your code will still run correctly, but progress bars may not display properly.\n",
    "\n",
    "# Option 1: Install/update ipywidgets (recommended if you want progress bars)\n",
    "# Uncomment and run the line below:\n",
    "# !pip install --upgrade ipywidgets jupyter\n",
    "\n",
    "# Option 2: Use text-based progress bars instead of widgets\n",
    "# Uncomment the line below to disable widgets (progress bars will still work, just as text):\n",
    "# import os; os.environ['TQDM_DISABLE'] = '1'\n",
    "\n",
    "# Note: You can safely ignore this warning - it won't prevent your code from running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17172,
     "status": "ok",
     "timestamp": 1678711240751,
     "user": {
      "displayName": "Sui Mai",
      "userId": "09591388850972871883"
     },
     "user_tz": -60
    },
    "id": "3_XrP3rUlEop",
    "outputId": "c19be0a9-a9c9-46bf-eef5-200780a3494c"
   },
   "outputs": [],
   "source": [
    "# textBert_utils.py is imported as a module in later cells, not run directly\n",
    "# The file exists in the same directory as this notebook\n",
    "print(\"textBert_utils.py is available and will be imported as needed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2299,
     "status": "ok",
     "timestamp": 1678711243035,
     "user": {
      "displayName": "Sui Mai",
      "userId": "09591388850972871883"
     },
     "user_tz": -60
    },
    "id": "DfB8X3Ldn7Ci",
    "outputId": "15f4893d-45c7-4162-a49f-3195ce08cffd"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():\n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FcFSbljwoMmO"
   },
   "source": [
    "## Install Huggingface Library\n",
    "\n",
    "These should have been installed during your environment set-up; you only need to run these cells in Google Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rodBL17AuSJ6"
   },
   "source": [
    "## Import Required Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project directory to sys.path to allow importing local modules\n",
    "# Find the directory containing textBert_utils.py (notebook's directory)\n",
    "current_dir = os.getcwd()\n",
    "project_dir = None\n",
    "\n",
    "# Search for textBert_utils.py in multiple possible locations\n",
    "search_dirs = [\n",
    "    current_dir,  # Current working directory\n",
    "    os.path.join(current_dir, 'Livability_evaluation_baseline'),  # Subdirectory of current\n",
    "    os.path.join(os.path.dirname(current_dir), 'Livability_evaluation_baseline'),  # Parent's subdirectory\n",
    "]\n",
    "\n",
    "# Also search parent directory and its subdirectories\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "if parent_dir != current_dir:\n",
    "    search_dirs.extend([\n",
    "        parent_dir,\n",
    "        os.path.join(parent_dir, 'Livability_evaluation_baseline'),\n",
    "    ])\n",
    "\n",
    "# Search all possible directories\n",
    "for dir_path in search_dirs:\n",
    "    dir_path = os.path.abspath(dir_path)\n",
    "    test_file = os.path.join(dir_path, 'textBert_utils.py')\n",
    "    if os.path.exists(test_file):\n",
    "        project_dir = dir_path\n",
    "        print(f'Found textBert_utils.py in: {project_dir}')\n",
    "        break\n",
    "\n",
    "# If still not found, try to search recursively in parent directories\n",
    "if project_dir is None:\n",
    "    search_path = current_dir\n",
    "    for _ in range(3):  # Search up to 3 levels up\n",
    "        test_file = os.path.join(search_path, 'textBert_utils.py')\n",
    "        if os.path.exists(test_file):\n",
    "            project_dir = search_path\n",
    "            print(f'Found textBert_utils.py in: {project_dir}')\n",
    "            break\n",
    "        # Also check Livability_evaluation_baseline subdirectory\n",
    "        subdir = os.path.join(search_path, 'Livability_evaluation_baseline')\n",
    "        if os.path.exists(os.path.join(subdir, 'textBert_utils.py')):\n",
    "            project_dir = subdir\n",
    "            print(f'Found textBert_utils.py in: {project_dir}')\n",
    "            break\n",
    "        search_path = os.path.dirname(search_path)\n",
    "        if search_path == os.path.dirname(search_path):  # Reached root\n",
    "            break\n",
    "\n",
    "# If still not found, use current directory\n",
    "if project_dir is None:\n",
    "    project_dir = current_dir\n",
    "    print(f'Warning: textBert_utils.py not found, using current directory: {project_dir}')\n",
    "\n",
    "# Add to sys.path if not already there\n",
    "if project_dir not in sys.path:\n",
    "    sys.path.insert(0, project_dir)\n",
    "    print(f'Added {project_dir} to sys.path')\n",
    "\n",
    "# Verify the file exists\n",
    "if os.path.exists(os.path.join(project_dir, 'textBert_utils.py')):\n",
    "    print(f'âœ“ textBert_utils.py found in project directory')\n",
    "else:\n",
    "    print(f'âœ— textBert_utils.py NOT found in project directory: {project_dir}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11079,
     "status": "ok",
     "timestamp": 1678711254099,
     "user": {
      "displayName": "Sui Mai",
      "userId": "09591388850972871883"
     },
     "user_tz": -60
    },
    "id": "UPMgkUw0WJvj"
   },
   "outputs": [],
   "source": [
    "from textBert_utils import set_seed\n",
    "from MMBT_liva.image_liva import ImageEncoderDenseNet\n",
    "from MMBT_liva.mmbt_config_liva import MMBTConfig\n",
    "from MMBT_liva.mmbt_liva import MMBTForClassification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 762,
     "status": "ok",
     "timestamp": 1678711254844,
     "user": {
      "displayName": "Sui Mai",
      "userId": "09591388850972871883"
     },
     "user_tz": -60
    },
    "id": "sqM0DScsmCnX"
   },
   "outputs": [],
   "source": [
    "from MMBT_liva.mmbt_utils_liva_0318 import JsonlDataset, get_image_transforms, get_labels, load_examples, collate_fn, get_multiclass_labels, get_multiclass_criterion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from MMBT_liva.mmbt_utils_liva_0318 import get_image_transforms, get_image_transforms_gray, get_image_transforms_giu\n",
    "\n",
    "class HFDatasetWrapper(Dataset):\n",
    "    def __init__(self, hf_dataset, tokenizer, transforms, transforms_gray, transforms_giu, max_seq_length):\n",
    "        self.dataset = hf_dataset\n",
    "        self.tokenizer = tokenizer\n",
    "        self.n_classes = 6\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.transforms = transforms\n",
    "        self.transforms_gray = transforms_gray\n",
    "        self.transforms_giu = transforms_giu\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        item = self.dataset[index]\n",
    "        \n",
    "        # Text encoding\n",
    "        sentence = torch.LongTensor(self.tokenizer.encode(item[\"text\"], add_special_tokens=True))\n",
    "        start_token, sentence, end_token = sentence[0], sentence[1:-1], sentence[-1]\n",
    "        sentence = sentence[:self.max_seq_length]\n",
    "\n",
    "        # Labels\n",
    "        label = torch.zeros(self.n_classes)\n",
    "        label[0] = float(item[\"lbm\"])\n",
    "        label[1] = float(item[\"fys\"])\n",
    "        label[2] = float(item[\"onv\"])\n",
    "        label[3] = float(item[\"soc\"])\n",
    "        label[4] = float(item[\"vrz\"])\n",
    "        label[5] = float(item[\"won\"])\n",
    "\n",
    "        # Images from HF are already PIL images\n",
    "        rs = item[\"rs_image\"].convert(\"RGB\")\n",
    "        rs = self.transforms(rs)\n",
    "\n",
    "        dsm = item[\"dsm_image\"].convert(\"RGB\")\n",
    "        dsm = self.transforms_gray(dsm)\n",
    "        \n",
    "        giu = item[\"giu_image\"].convert(\"RGB\")\n",
    "        giu = self.transforms_giu(giu)\n",
    "\n",
    "        # Concatenate 3 images along channel dimension (3+3+3 = 9 channels)\n",
    "        image_3 = torch.cat((rs, dsm, giu), dim=0)\n",
    "        \n",
    "        return {\n",
    "            \"image_start_token\": start_token,\n",
    "            \"image_end_token\": end_token,\n",
    "            \"sentence\": sentence,\n",
    "            \"image\": image_3,\n",
    "            \"label\": label,\n",
    "        }\n",
    "\n",
    "def load_examples(tokenizer, wandb_config, evaluate=False, test=False, **kwargs):\n",
    "    \"\"\"Overriding load_examples to use Hugging Face dataset\"\"\"\n",
    "    print(f\"Loading dataset 'Vinjou/Multimodal_urban_livability_evaluation_dataset' from Hugging Face... (evaluate={evaluate}, test={test})\")\n",
    "    # Try to load dataset with token if available\n",
    "    try:\n",
    "        # First, try with token from environment or Hugging Face cache\n",
    "        import os\n",
    "        from huggingface_hub import HfFolder\n",
    "        token = os.environ.get(\"HF_TOKEN\") or HfFolder.get_token()\n",
    "        \n",
    "        if not token:\n",
    "            raise RuntimeError(\"HF token missing. Please set HF_TOKEN environment variable or run huggingface-cli login.\")\n",
    "        \n",
    "        # Load dataset with token\n",
    "        hf_dataset_dict = load_dataset(\"Vinjou/Multimodal_urban_livability_evaluation_dataset\", token=token)\n",
    "    except Exception as e:\n",
    "        # If loading fails, provide helpful error message\n",
    "        error_msg = str(e)\n",
    "        if \"Unauthorized\" in error_msg or \"token\" in error_msg.lower():\n",
    "            print(\"âŒ Authentication required to access the dataset.\")\n",
    "            print(\"Please login to Hugging Face using one of the following methods:\")\n",
    "            print(\"  1. Run: huggingface-cli login\")\n",
    "            print(\"  2. Or set environment variable: export HF_TOKEN=your_token\")\n",
    "            print(\"  3. Or pass token directly: load_dataset(..., token=your_token)\")\n",
    "        raise\n",
    "    \n",
    "    if evaluate and not test:\n",
    "        hf_dataset = hf_dataset_dict[\"validation\"]\n",
    "    elif evaluate and test:\n",
    "        hf_dataset = hf_dataset_dict[\"test\"]\n",
    "    else:\n",
    "        hf_dataset = hf_dataset_dict[\"train\"]\n",
    "\n",
    "    img_transforms = get_image_transforms()\n",
    "    img_transforms_gray = get_image_transforms_gray()\n",
    "    img_transforms_giu = get_image_transforms_giu()\n",
    "\n",
    "    dataset = HFDatasetWrapper(\n",
    "        hf_dataset, \n",
    "        tokenizer, \n",
    "        img_transforms, \n",
    "        img_transforms_gray, \n",
    "        img_transforms_giu, \n",
    "        wandb_config.max_seq_length - wandb_config.num_image_embeds - 2\n",
    "    )\n",
    "    return dataset\n",
    "\n",
    "def hf_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Specify batching for the Hugging Face dataset\n",
    "    \"\"\"\n",
    "    lens = [len(row[\"sentence\"]) for row in batch]\n",
    "    bsz, max_seq_len = len(batch), max(lens)\n",
    "\n",
    "    mask_tensor = torch.zeros(bsz, max_seq_len, dtype=torch.long)\n",
    "    text_tensor = torch.zeros(bsz, max_seq_len, dtype=torch.long)\n",
    "\n",
    "    for i_batch, (input_row, length) in enumerate(zip(batch, lens)):\n",
    "        text_tensor[i_batch, :length] = input_row[\"sentence\"]\n",
    "        mask_tensor[i_batch, :length] = 1\n",
    "\n",
    "    img_tensor = torch.stack([row[\"image\"] for row in batch])\n",
    "    tgt_tensor = torch.stack([row[\"label\"] for row in batch])\n",
    "    img_start_token = torch.stack([row[\"image_start_token\"] for row in batch])\n",
    "    img_end_token = torch.stack([row[\"image_end_token\"] for row in batch])\n",
    "\n",
    "    return {\n",
    "        \"sentence\": text_tensor,\n",
    "        \"attention_mask\": mask_tensor,\n",
    "        \"image\": img_tensor,\n",
    "        \"image_start_token\": img_start_token,\n",
    "        \"image_end_token\": img_end_token,\n",
    "        \"label\": tgt_tensor\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1678711254847,
     "user": {
      "displayName": "Sui Mai",
      "userId": "09591388850972871883"
     },
     "user_tz": -60
    },
    "id": "0wUXVNbSoBVo"
   },
   "outputs": [],
   "source": [
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1678711254849,
     "user": {
      "displayName": "Sui Mai",
      "userId": "09591388850972871883"
     },
     "user_tz": -60
    },
    "id": "Th_vPKXcpn4R"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import logging\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1678711254850,
     "user": {
      "displayName": "Sui Mai",
      "userId": "09591388850972871883"
     },
     "user_tz": -60
    },
    "id": "lWUF76E4y1CC"
   },
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, precision_score, recall_score, multilabel_confusion_matrix, hamming_loss, classification_report\n",
    "# Disable Jupyter widgets for tqdm to avoid version compatibility warnings\n",
    "import os\n",
    "os.environ['TQDM_DISABLE'] = '1'\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from transformers import (\n",
    "    WEIGHTS_NAME,\n",
    "    AutoConfig,\n",
    "    AutoModel,\n",
    "    AutoTokenizer,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")\n",
    "\n",
    "try:\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "except ImportError:\n",
    "    from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ç±»åˆ«åˆ†å¸ƒç»Ÿè®¡ï¼ˆflood_degreeï¼‰\n",
      "============================================================\n",
      "  ç±»åˆ« 0: 1447 ä¸ªæ ·æœ¬\n",
      "  ç±»åˆ« 1: 292 ä¸ªæ ·æœ¬\n",
      "  ç±»åˆ« 2: 1407 ä¸ªæ ·æœ¬\n",
      "  ç±»åˆ« 3: 1335 ä¸ªæ ·æœ¬\n",
      "  ç±»åˆ« 4: 469 ä¸ªæ ·æœ¬\n",
      "\n",
      "è®¡ç®—å¾—åˆ°çš„ç±»åˆ«æƒé‡ï¼ˆbalancedï¼‰:\n",
      "  ç±»åˆ« 0: 0.6842\n",
      "  ç±»åˆ« 1: 3.3904\n",
      "  ç±»åˆ« 2: 0.7036\n",
      "  ç±»åˆ« 3: 0.7416\n",
      "  ç±»åˆ« 4: 2.1109\n",
      "\n",
      "å½’ä¸€åŒ–åŽçš„ç±»åˆ«æƒé‡ï¼ˆå¹³å‡æƒé‡=1ï¼‰:\n",
      "  ç±»åˆ« 0: 0.4483\n",
      "  ç±»åˆ« 1: 2.2216\n",
      "  ç±»åˆ« 2: 0.6455\n",
      "  ç±»åˆ« 3: 0.7289\n",
      "  ç±»åˆ« 4: 1.3832\n",
      "\n",
      "ðŸ“Š ç±»åˆ«æƒé‡è°ƒæ•´ï¼ˆv4ç‰ˆæœ¬ä¼˜åŒ–ï¼‰:\n",
      "   åŽŸå§‹æƒé‡ â†’ è°ƒæ•´åŽæƒé‡\n",
      "   ç±»åˆ« 0: 0.4483 â†’ 0.4483 (+0.0%)\n",
      "   ç±»åˆ« 1: 2.2216 â†’ 2.2216 (+0.0%)\n",
      "   ç±»åˆ« 2: 0.4611 â†’ 0.6455 (+40.0%)\n",
      "   ç±»åˆ« 3: 0.4859 â†’ 0.7289 (+50.0%)\n",
      "   ç±»åˆ« 4: 1.3832 â†’ 1.3832 (+0.0%)\n",
      "\n",
      "âœ… ç±»åˆ«æƒé‡è®¡ç®—å®Œæˆ\n",
      "ðŸ’¡ è¿™äº›æƒé‡å°†ç”¨äºŽFocal Lossï¼ˆv4ç‰ˆæœ¬æ”¹è¿›ï¼‰ä»¥å¤„ç†ç±»åˆ«ä¸å¹³è¡¡å¹¶å…³æ³¨éš¾åˆ†ç±»æ ·æœ¬\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Calculate Class Weights (Handling Class Imbalance)\n",
    "# ============================================\n",
    "# Calculate inverse frequency weighted weights bystatisticsclass distribution from training data\n",
    "import json\n",
    "from collections import Counter\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "# Load training data\n",
    "train_file = \"/u/wz53/Flooding/Flooding_codes/Cross_attention_Transformer/dataset_json_5degree/1216_5height_degree_train.json\"\n",
    "try:\n",
    "    with open(train_file, 'r', encoding='utf-8') as f:\n",
    "        train_data = json.load(f)\n",
    "    \n",
    "    # Extract flood_degree labels\n",
    "    flood_degree_labels = []\n",
    "    data_list = train_data.get('data', []) or train_data.get('records', [])\n",
    "    \n",
    "    for item in data_list:\n",
    "        fd = item.get(\"flood_degree\")\n",
    "        if fd is not None:\n",
    "            flood_degree_labels.append(int(fd))\n",
    "    \n",
    "    # Statistics of class distribution\n",
    "    class_counts = Counter(flood_degree_labels)\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Class Distribution Statistics (flood_degree)\")\n",
    "    print(\"=\" * 60)\n",
    "    for cls in sorted(class_counts.keys()):\n",
    "        print(f\"  Class {cls}: {class_counts[cls]}  samples\")\n",
    "    \n",
    "    # calculateClassweights(using sklearn's balanced method)\n",
    "    classes = sorted(class_counts.keys())\n",
    "    import numpy as np\n",
    "    # Convert classes and labels to numpy arrays\n",
    "    classes = np.array(sorted(class_counts.keys()))\n",
    "    flood_degree_labels = np.array(flood_degree_labels)\n",
    "    \n",
    "    class_weights = compute_class_weight('balanced', classes=classes, y=flood_degree_labels)\n",
    "    class_weights_dict = {cls: weight for cls, weight in zip(classes, class_weights)}\n",
    "    \n",
    "    print(\"\\nCalculated class weights (balanced):\")\n",
    "    for cls in sorted(classes):\n",
    "        print(f\"  Class {cls}: {class_weights_dict[cls]:.4f}\")\n",
    "    \n",
    "    # Convert to tensor format (for model)\n",
    "    max_class = max(classes)\n",
    "    class_weights_tensor = torch.zeros(max_class + 1, dtype=torch.float32)\n",
    "    for cls, weight in class_weights_dict.items():\n",
    "        class_weights_tensor[cls] = weight\n",
    "    \n",
    "    # Normalize weights so that average weight is 1 (consistent with model code processing)\n",
    "    class_weights_tensor = class_weights_tensor / class_weights_tensor.mean()\n",
    "    # ============================================\n",
    "    # v4 Version Improvement: Increase weights for Class 2 and Class 3(improve performance on difficult-to-classify classes)\n",
    "    # ============================================\n",
    "    # Classes 2 and 3 had the most severe F1 drops in v2 version (3.35% and 4.63% respectively)\n",
    "    # Increase weights for these classes to make the model focus more on difficult-to-classify samples\n",
    "    original_weights = class_weights_tensor.clone()\n",
    "    if len(class_weights_tensor) >= 3:\n",
    "        # Class2(index 2)ï¼šIncrease weight by approximately 40%\n",
    "        class_weights_tensor[2] = class_weights_tensor[2] * 1.4\n",
    "    if len(class_weights_tensor) >= 4:\n",
    "        # Class3(index 3)ï¼šIncrease weight by approximately 50%\n",
    "        class_weights_tensor[3] = class_weights_tensor[3] * 1.5\n",
    "    \n",
    "    print(\"\\nNormalized class weights (average weight = 1):\")\n",
    "    for cls in range(len(class_weights_tensor)):\n",
    "        if cls in classes:\n",
    "            print(f\"  Class {cls}: {class_weights_tensor[cls]:.4f}\")\n",
    "    \n",
    "    print(\"\\nðŸ“Š Class Weight Adjustment (v4 version optimization):\")\n",
    "    print(\"   Original weight â†’ Adjusted weight\")\n",
    "    for cls in classes:\n",
    "        orig_w = original_weights[cls].item()\n",
    "        new_w = class_weights_tensor[cls].item()\n",
    "        change_pct = ((new_w - orig_w) / orig_w * 100) if orig_w > 0 else 0\n",
    "        print(f\"   Class {cls}: {orig_w:.4f} â†’ {new_w:.4f} ({change_pct:+.1f}%)\")\n",
    "    \n",
    "    # Save class weights to global variable for model use\n",
    "    GLOBAL_CLASS_WEIGHTS = class_weights_tensor\n",
    "    GLOBAL_CLASS_COUNTS = {cls: class_counts[cls] for cls in classes}\n",
    "    \n",
    "    print(\"\\nâœ… Class weight calculation completed\")\n",
    "    print(\"ðŸ’¡ These weights will be used for Focal Loss (v4 version improvement) to handle class imbalance and focus on difficult-to-classify samples\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Failed to calculate class weights: {e}\")\n",
    "    print(\"ðŸ’¡ Will use default weights in model\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    GLOBAL_CLASS_WEIGHTS = None\n",
    "    GLOBAL_CLASS_COUNTS = None\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aWgdU7lBnyFd"
   },
   "source": [
    "# Set-up Experiment Hyperparameters and Arguments\n",
    "\n",
    "Specify the training, validation, and test files to run the experiment on. The default here is running the model on 'impression' texts.  \n",
    "\n",
    "To re-make the training, validation, and test data, please refer to the information in the **data/** directory.  \n",
    "\n",
    "Change the default values in the parser.add_argument function for the hyperparameters that you want to specify in the following cell or use the default option.  \n",
    "\n",
    "For multiple experiment runs, please make sure to change the `output_dir` argument so that new results don't overwrit existing ones.\n",
    "\n",
    "The arguments specified here are the same as in the `run_mmimdb.py` file \n",
    "in the [Huggingface example implementation of MMBT.](https://github.com/huggingface/transformers/blob/8ea412a86faa8e9edeeb6b5c46b08def06aa03ea/examples/research_projects/mm-imdb/run_mmimdb.py#L305)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Or ignore specific types of warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1678711254851,
     "user": {
      "displayName": "Sui Mai",
      "userId": "09591388850972871883"
     },
     "user_tz": -60
    },
    "id": "urly6ofboEmU"
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(f'Project Hyperparameters and Other Configurations Argument Parser')\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# Required parameters\n",
    "parser.add_argument(\n",
    "    \"--model_name\",\n",
    "    default=\"bert-base-multilingual-uncased\", \n",
    "    type=str,\n",
    "    help=\"model identifier from huggingface.co/models\",\n",
    ")\n",
    "#Change this if the input is Chinese,bert-base-uncased(trained on lowercase English text.) 2 bert-base-chinese(trained on simplified and traditional Chinese text with 12 hidden layers and 110M parameters.) \n",
    "parser.add_argument(\n",
    "    \"--output_dir\",\n",
    "    default=\"livability_4M_6aspects\", #   mmbt_output_findings_10epochs_n\n",
    "    type=str,\n",
    "    help=\"The output directory where the model predictions and checkpoints will be written.\",\n",
    ")\n",
    "\n",
    "    \n",
    "parser.add_argument(\n",
    "    \"--config_name\", default=\"bert-base-multilingual-uncased\", type=str, help=\"Pretrained config name if not the same as model_name\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--tokenizer_name\",\n",
    "    default=\"bert-base-multilingual-uncased\",\n",
    "    type=str,\n",
    "    help=\"Pretrained tokenizer name or path if not the same as model_name\",\n",
    ")\n",
    "\n",
    "parser.add_argument(\"--train_batch_size\", default=16, type=int, help=\"Batch size for training.\") #Changed from 32 to 16 -20;If set to 14, move last 4 eval samples to train.\n",
    "parser.add_argument(\n",
    "    \"--eval_batch_size\", default=16, type=int, help=\"Batch size for evaluation.\" #Changed from 32 to 16  -20 #Set to 1 for attention visualization\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--max_seq_length\",\n",
    "    default=400,#50,  #Originally 300, max 512\n",
    "    type=int,\n",
    "    help=\"The maximum total input sequence length after tokenization. Sequences longer \"\n",
    "    \"than this will be truncated, sequences shorter will be padded.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--num_image_embeds\", default=9, type=int, help=\"Number of Image Embeddings from the Image Encoder\" # 3chanel *3 images\n",
    ") # B*N*1024 (batch * num_image_embeds * 1024)\n",
    "parser.add_argument(\"--do_train\", default=False, type=bool, help=\"Whether to run training.\") # Modified for testing only\n",
    "parser.add_argument(\"--do_eval\", default=True, type=bool, help=\"Whether to run eval on the dev set.\")\n",
    "parser.add_argument(\n",
    "    \"--evaluate_during_training\", default=True, type=bool, help=\"Run evaluation during training at each logging step.\"\n",
    ")\n",
    "\n",
    "\n",
    "parser.add_argument(\n",
    "    \"--gradient_accumulation_steps\",\n",
    "    type=int,\n",
    "    default=1,\n",
    "    help=\"Number of updates steps to accumulate before performing a backward/update pass.\",\n",
    ")\n",
    "parser.add_argument(\"--learning_rate\", default=5e-05, type=float, help=\"The initial learning rate for Adam.\") # originally default=5e-5 (0.00005);\n",
    "parser.add_argument(\"--weight_decay\", default=0.1, type=float, help=\"Weight deay if we apply some.\")\n",
    "parser.add_argument(\"--adam_epsilon\", default=1e-8, type=float, help=\"Epsilon for Adam optimizer.\")\n",
    "parser.add_argument(\"--max_grad_norm\", default=1.0, type=float, help=\"Max gradient norm.\")\n",
    "parser.add_argument(\n",
    "    \"--num_train_epochs\", default=1, type=float, help=\"Total number of training epochs to perform.\"# HuggingFace default is 3, previous experiment used 10.\n",
    ")\n",
    "parser.add_argument(\"--patience\", default=5, type=int, help=\"Patience for Early Stopping.\")\n",
    "parser.add_argument(\n",
    "    \"--max_steps\",\n",
    "    default=-1,\n",
    "    type=int,\n",
    "    help=\"If > 0: set total number of training steps to perform. Override num_train_epochs.\",\n",
    ")\n",
    "parser.add_argument(\"--warmup_steps\", default=0, type=int, help=\"Linear warmup over warmup_steps.\") #When warmup_steps is 0, there is no warmup,only linear decay to 0\n",
    "\n",
    "parser.add_argument(\"--logging_steps\", type=int, default=50, help=\"Log every X updates steps.\") #Originally 25,\n",
    "parser.add_argument(\"--save_steps\", type=int, default=50, help=\"Save checkpoint every X updates steps.\") #Originally 25,\n",
    "parser.add_argument(\n",
    "    \"--eval_all_checkpoints\",\n",
    "    default=True, type=bool,\n",
    "    help=\"Evaluate all checkpoints starting with the same prefix as model_name ending and ending with step number\",\n",
    ")\n",
    "\n",
    "parser.add_argument(\"--num_workers\", type=int, default=8, help=\"number of worker threads for dataloading\")\n",
    "\n",
    "parser.add_argument(\"--seed\", type=int, default=42, help=\"random seed for initialization\")\n",
    "\n",
    "\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "# Setup CUDA, GPU & distributed training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "args.n_gpu = torch.cuda.device_count() if torch.cuda.is_available() else 0\n",
    "args.device = device\n",
    "\n",
    "# for multiclass labeling\n",
    "args.multiclass = True #Modification 1:args.multiclass = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lKOToFXcKxs1"
   },
   "source": [
    "## Showing a sample from JsonDataset\n",
    "i.e. calling \"\\_\\_getitem\\_\\_\"\n",
    "\n",
    "Note:   \n",
    "image_end_token is the BERT token id for [SEP].   \n",
    "image_start_token is the BERT token id for [CLS]. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "894ce7267bde4252a68e4f538de90b86",
      "0d9117147b0a413c98cd76112c67b3a6",
      "c743a9299c784dbf91fb209e30de9c7c",
      "85e5c7f55dac42dea724729db70e01fa",
      "a3f564f3b8cf4be1988863320a4682ea",
      "ce4dc208e7794b99b001d63adc03f196",
      "91a737e1134544afa343640f1cb7a5ca",
      "80574460226a475d977299562fbed072",
      "72ed8b9958614dfda0b3d3bdf6d71378",
      "3e68b4254b8a41249797f99cab88d4f3",
      "7b67bc5234ef46c496738e9acb1edb20",
      "85591e73ae574650916daf40a877326c",
      "b3a612e6191a496dbff4d55cee76af73",
      "22e78ff34aa5401d93f2b6afeeef36a7",
      "21a7ceb4d8384c4fb75fa6cfa979824b",
      "97ace72d1e274732ab8ab5b7e762b5e3",
      "747bc2afec7a4f4d9c0bea4e8498e0cd",
      "c65b23c4d46747c7b0d9968348ec15fc",
      "7867862f9b354bbc9b84a2977ae6eff8",
      "31c54a05d50140b192a0fdf56d647694",
      "269e9c6d072842f998af2e3cc55ebada",
      "400f1ce98b894d1c8f3bdd32c08377a7",
      "ceac6d587533457cb9d2eed0a1ebdba8",
      "44ed7fe967414a3db9ecda413660f2d6",
      "f95c21c708fa4923a8b49fb8209c39a2",
      "7f1f8393330f459ba14e11d4bc5cbb07",
      "970ff7dc97234313ab994ab80152fdff",
      "6c97deab4fee41f592167ddce3223c0e",
      "bde88ca9771c44f285664c5fe74222c7",
      "8ec5350d0c984b75a128e79472c5a10f",
      "0ff36347a90a42e4a705f91d07f99324",
      "fa4126b6651c411fa63fb800b9478c95",
      "34ed8ad093ec4a3cbeff7454279a11d8",
      "e5622b66d7c14a49bd6d8f45b2ce5afc",
      "cbdce03e88604e97881fcf5a9e6bbc33",
      "5081b02dc8de435e9033c7dcb82b0962",
      "f825f26d6a6e47f0b5d6371f5177bcd5",
      "dd69a4af9fdb46f484f1873101cdc1ff",
      "b31b075eaf1844aaa45b534425b5b2a7",
      "84df966af26b4850812e4b84a7c2baaa",
      "f74d8d4596b4472fbda6663375565e59",
      "b9c1593889fb4795bb58e8f798408235",
      "8b2c9d0a6d72481b96ee7d7cf3d79d03",
      "270e4d4761f944d083e45af13ff50ee2"
     ]
    },
    "executionInfo": {
     "elapsed": 4991,
     "status": "ok",
     "timestamp": 1678711259829,
     "user": {
      "displayName": "Sui Mai",
      "userId": "09591388850972871883"
     },
     "user_tz": -60
    },
    "id": "h_cC7-CQFKyP",
    "outputId": "fd8cb58c-ded6-4ea5-e2e5-97356f3654fd"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "        args.tokenizer_name if args.tokenizer_name else args.model_name,\n",
    "        do_lower_case=True,\n",
    "        cache_dir=None,\n",
    "    )\n",
    "train_dataset = load_examples(tokenizer, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# Assume tgts and preds are already defined and calculated\n",
    "# tgts and preds are multi-dimensional tensors, where each column corresponds to a different label\n",
    "\n",
    "\n",
    "def plot_density_scatter(tgts, preds, label, ax, xlim, ylim):\n",
    "    \"\"\"\n",
    "    Plot density scatter plot and set axis range\n",
    "    \"\"\"\n",
    "    # Calculate density\n",
    "    xy = np.vstack([tgts, preds])\n",
    "    z = gaussian_kde(xy)(xy)\n",
    "    \n",
    "    # Plot scatter plot\n",
    "    scatter = ax.scatter(tgts, preds, c=z, s=5, edgecolor=None, cmap='viridis')\n",
    "    \n",
    "    # Add color bar\n",
    "    cbar = plt.colorbar(scatter, ax=ax)\n",
    "    cbar.set_label('Density')\n",
    "    \n",
    "    ax.set_xlabel(f'Ground Truth of {label}')\n",
    "    ax.set_ylabel(f'Predicted value of {label}')\n",
    "    ax.set_title(f'Density Scatter Plot of {label}')\n",
    "    ax.grid(True)\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_ylim(ylim)\n",
    "    ax.set_aspect('equal', adjustable='box')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v_qY3Xe7Owyq"
   },
   "source": [
    "\n",
    "### Training and Evaluating Functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, train_dataset, model, tokenizer):\n",
    "    \"\"\" Train the model \"\"\"\n",
    "    \n",
    "    # add the specified batch size and output dir for current run to Tensorboard \n",
    "    # saved run's name for easy identification\n",
    "    comment = f\"train_{args.output_dir}_{args.train_batch_size}\"\n",
    "    try:\n",
    "        from torch.utils.tensorboard import SummaryWriter\n",
    "    except ImportError:\n",
    "        from tensorboardX import SummaryWriter\n",
    "    tb_writer = SummaryWriter(comment=comment)\n",
    "\n",
    "    train_sampler = RandomSampler(train_dataset)\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        sampler=train_sampler,\n",
    "        batch_size=args.train_batch_size,\n",
    "        collate_fn=hf_collate_fn\n",
    "    )\n",
    "\n",
    "    t_total = len(train_dataloader) // args.gradient_accumulation_steps * args.num_train_epochs\n",
    "\n",
    "    # Prepare optimizer and schedule (linear warmup and decay)\n",
    "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_grouped_parameters = [\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": args.weight_decay,\n",
    "        },\n",
    "        {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
    "    ]\n",
    "\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=args.adam_epsilon)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, num_warmup_steps=args.warmup_steps, num_training_steps=t_total\n",
    "    )\n",
    "    \n",
    "\n",
    "    # Train!\n",
    "    logger.info(\"***** Running training *****\")\n",
    "    logger.info(\"  Num examples = %d\", len(train_dataset))\n",
    "    logger.info(\"  Num Epochs = %d\", args.num_train_epochs)\n",
    "    logger.info(\n",
    "        \"  Total train batch size = %d\",\n",
    "        args.train_batch_size\n",
    "        * args.gradient_accumulation_steps)\n",
    "    logger.info(\"  Gradient Accumulation steps = %d\", args.gradient_accumulation_steps)\n",
    "    logger.info(\"  Total optimization steps = %d\", t_total)\n",
    "\n",
    "    global_step = 0\n",
    "    tr_loss, logging_loss = 0.0, 0.0\n",
    "    best_eval_metric, n_no_improve = 0, 0\n",
    "    model.train()\n",
    "    model.zero_grad()\n",
    "    optimizer.zero_grad()\n",
    "    train_iterator = trange(int(args.num_train_epochs), desc=\"Epoch\")\n",
    "    set_seed(args)  # Added here for reproducibility\n",
    "\n",
    "    for _ in train_iterator:\n",
    "        epoch_iterator = tqdm(train_dataloader, desc=\"Training Batch Iteration\")\n",
    "        for step, batch in enumerate(epoch_iterator):\n",
    "            # batch content is determined by collate_fn\n",
    "            \n",
    "            # Move batch tensors to device\n",
    "            # Note: batch is now a dict from HFDatasetWrapper\n",
    "            input_ids = batch[\"sentence\"].to(args.device)\n",
    "            input_modal = batch[\"image\"].to(args.device)\n",
    "            labels = batch[\"label\"].to(args.device)\n",
    "            modal_start_tokens = batch[\"image_start_token\"].to(args.device)\n",
    "            modal_end_tokens = batch[\"image_end_token\"].to(args.device)\n",
    "            \n",
    "            if \"attention_mask\" in batch:\n",
    "                attention_mask = batch[\"attention_mask\"].to(args.device)\n",
    "            else:\n",
    "                attention_mask = torch.ones_like(input_ids).to(args.device)\n",
    "\n",
    "            if args.multiclass:\n",
    "                outputs = model(\n",
    "                    input_modal,\n",
    "                    input_ids=input_ids,\n",
    "                    modal_start_tokens=modal_start_tokens,\n",
    "                    modal_end_tokens=modal_end_tokens,\n",
    "                    attention_mask=attention_mask,\n",
    "                    token_type_ids=None,\n",
    "                    modal_token_type_ids=None,\n",
    "                    position_ids=None,\n",
    "                    modal_position_ids=None,\n",
    "                    head_mask=None,\n",
    "                    inputs_embeds=None,\n",
    "                    labels=None,\n",
    "                    return_dict=True\n",
    "                )\n",
    "            else:\n",
    "                outputs = model(\n",
    "                    input_modal,\n",
    "                    input_ids=input_ids,\n",
    "                    modal_start_tokens=modal_start_tokens,\n",
    "                    modal_end_tokens=modal_end_tokens,\n",
    "                    attention_mask=attention_mask,\n",
    "                    token_type_ids=None,\n",
    "                    modal_token_type_ids=None,\n",
    "                    position_ids=None,\n",
    "                    modal_position_ids=None,\n",
    "                    head_mask=None,\n",
    "                    inputs_embeds=None,\n",
    "                    labels=None,\n",
    "                    return_dict=True\n",
    "                )\n",
    "            \n",
    "            logits = outputs.logits\n",
    "\n",
    "            if args.multiclass:\n",
    "                my_loss = torch.nn.SmoothL1Loss()\n",
    "                loss = my_loss(logits, labels) # prediction first, target second\n",
    "            else:\n",
    "                criterion = get_multiclass_criterion(train_dataset)\n",
    "                loss = criterion(logits, labels)\n",
    "            \n",
    "            \n",
    "            if args.n_gpu > 1:\n",
    "                loss = loss.mean()  # mean() to average on multi-gpu parallel training\n",
    "            if args.gradient_accumulation_steps > 1:\n",
    "                loss = loss / args.gradient_accumulation_steps\n",
    "\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            tr_loss += loss.item()\n",
    "            if (step + 1) % args.gradient_accumulation_steps == 0:\n",
    "\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
    "\n",
    "                optimizer.step()\n",
    "                scheduler.step()  # Update learning rate schedule\n",
    "                model.zero_grad()\n",
    "                global_step += 1\n",
    "\n",
    "\n",
    "                if args.logging_steps > 0 and global_step % args.logging_steps == 0:\n",
    "                    logs = {}\n",
    "                    if args.evaluate_during_training:  \n",
    "                        # Only evaluate when single GPU otherwise metrics may not average well\n",
    "                        results = evaluate(args, model, tokenizer)\n",
    "                        for key, value in results.items():\n",
    "                            eval_key = \"eval_{}\".format(key)\n",
    "                            logs[eval_key] = value\n",
    "\n",
    "                    loss_scalar = (tr_loss - logging_loss) / args.logging_steps\n",
    "                    learning_rate_scalar = scheduler.get_last_lr()[0]\n",
    "                    logs[\"learning_rate\"] = learning_rate_scalar\n",
    "                    logs[\"training_loss\"] = loss_scalar\n",
    "                    logging_loss = tr_loss\n",
    "\n",
    "                    for key, value in logs.items():\n",
    "                        tb_writer.add_scalar(key, value, global_step)\n",
    "\n",
    "                    # debug: handle tensor to scalar for JSON serialization\n",
    "                    logs_serializable = {key: float(value.cpu().numpy()) if isinstance(value, torch.Tensor) else value for key, value in logs.items()}\n",
    "                    print(json.dumps(logs_serializable))\n",
    "\n",
    "                if args.save_steps > 0 and global_step % args.save_steps == 0:\n",
    "                    # Save model checkpoint\n",
    "                    output_dir = os.path.join(args.output_dir, f\"checkpoint-{global_step}\")\n",
    "                    if not os.path.exists(output_dir):\n",
    "                        os.makedirs(output_dir)\n",
    "                    model_to_save = (\n",
    "                        model.module if hasattr(model, \"module\") else model\n",
    "                    )  # Take care of distributed/parallel training\n",
    "                    torch.save(model_to_save.state_dict(), os.path.join(output_dir, WEIGHTS_NAME))\n",
    "                    logger.info(f\"Saving model checkpoint to {output_dir}\")\n",
    "\n",
    "\n",
    "        results = evaluate(args, model, tokenizer)\n",
    "        if args.multiclass:\n",
    "            eval_result = results[\"rmse_lbm\"]\n",
    "        else:\n",
    "            eval_result = results[\"macro_f1\"]\n",
    "\n",
    "        if eval_result > best_eval_metric:\n",
    "            best_eval_metric = eval_result\n",
    "            n_no_improve = 0\n",
    "        else:\n",
    "            n_no_improve += 1\n",
    "\n",
    "        if n_no_improve > args.patience:\n",
    "            train_iterator.close()\n",
    "            break\n",
    "\n",
    "    tb_writer.close()\n",
    "\n",
    "    return global_step, tr_loss / global_step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1678711259830,
     "user": {
      "displayName": "Sui Mai",
      "userId": "09591388850972871883"
     },
     "user_tz": -60
    },
    "id": "hwg0asA2Zm6P"
   },
   "outputs": [],
   "source": [
    "def evaluate(args, model, tokenizer, evaluate=True, test=False, prefix=\"\"):\n",
    "    \n",
    "    if test:\n",
    "        # start a separate tensorboard to track testing eval result\n",
    "        comment = f\"test_{args.output_dir}_{args.eval_batch_size}\"\n",
    "        try:\n",
    "            from torch.utils.tensorboard import SummaryWriter\n",
    "        except ImportError:\n",
    "            from tensorboardX import SummaryWriter\n",
    "        tb_writer = SummaryWriter(comment=comment)\n",
    "\n",
    "    eval_output_dir = args.output_dir\n",
    "    eval_dataset = load_examples(tokenizer, args, evaluate=evaluate, test=test)\n",
    "\n",
    "    if not os.path.exists(eval_output_dir):\n",
    "        os.makedirs(eval_output_dir)\n",
    "\n",
    "    \n",
    "    eval_sampler = SequentialSampler(eval_dataset)\n",
    "    eval_dataloader = DataLoader(\n",
    "        eval_dataset, sampler=eval_sampler, batch_size=args.eval_batch_size, collate_fn=hf_collate_fn\n",
    "    )\n",
    "\n",
    "    # Eval!\n",
    "    logger.info(f\"***** Running evaluation {prefix} *****\")\n",
    "    logger.info(f\"  Num examples = {len(eval_dataset)}\")\n",
    "    logger.info(f\"  Batch size = {args.eval_batch_size}\")\n",
    "    eval_loss = 0.0\n",
    "    nb_eval_steps = 0\n",
    "    preds = []\n",
    "    out_label_ids = []\n",
    "    for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
    "        model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Extract items from dictionary batch and move to device\n",
    "            input_ids = batch[\"sentence\"].to(args.device)\n",
    "            input_modal = batch[\"image\"].to(args.device)\n",
    "            labels = batch[\"label\"].to(args.device)\n",
    "            modal_start_tokens = batch[\"image_start_token\"].to(args.device)\n",
    "            modal_end_tokens = batch[\"image_end_token\"].to(args.device)\n",
    "            \n",
    "            if \"attention_mask\" in batch:\n",
    "                attention_mask = batch[\"attention_mask\"].to(args.device)\n",
    "            else:\n",
    "                attention_mask = torch.ones_like(input_ids).to(args.device)\n",
    "            \n",
    "            if args.multiclass:\n",
    "                outputs = model(\n",
    "                    input_modal,\n",
    "                    input_ids=input_ids,\n",
    "                    modal_start_tokens=modal_start_tokens,\n",
    "                    modal_end_tokens=modal_end_tokens,\n",
    "                    attention_mask=attention_mask,\n",
    "                    token_type_ids=None,\n",
    "                    modal_token_type_ids=None,\n",
    "                    position_ids=None,\n",
    "                    modal_position_ids=None,\n",
    "                    head_mask=None,\n",
    "                    inputs_embeds=None,\n",
    "                    labels=None,\n",
    "                    return_dict=True\n",
    "                )\n",
    "            else:\n",
    "                outputs = model(\n",
    "                    input_modal,\n",
    "                    input_ids=input_ids,\n",
    "                    modal_start_tokens=modal_start_tokens,\n",
    "                    modal_end_tokens=modal_end_tokens,\n",
    "                    attention_mask=attention_mask,\n",
    "                    token_type_ids=None,\n",
    "                    modal_token_type_ids=None,\n",
    "                    position_ids=None,\n",
    "                    modal_position_ids=None,\n",
    "                    head_mask=None,\n",
    "                    inputs_embeds=None,\n",
    "                    labels=None,\n",
    "                    return_dict=True\n",
    "                )\n",
    "            logits = outputs.logits\n",
    "\n",
    "            if args.multiclass:\n",
    "                my_loss = torch.nn.MSELoss()\n",
    "                tmp_eval_loss = my_loss(logits, labels)\n",
    "            else:\n",
    "                criterion = get_multiclass_criterion(eval_dataset)\n",
    "                tmp_eval_loss = criterion(logits, labels)                \n",
    "            eval_loss += tmp_eval_loss.mean().item()\n",
    "        nb_eval_steps += 1\n",
    "        \n",
    "        # Move logits and labels to CPU\n",
    "        if args.multiclass:\n",
    "            pred = logits.detach().cpu()\n",
    "        else:            \n",
    "            pred = torch.nn.functional.softmax(logits, dim=1).argmax(dim=1).cpu().detach().numpy()\n",
    "\n",
    "        if args.multiclass:\n",
    "            out_label_id = labels.detach().cpu()\n",
    "        else:\n",
    "            out_label_id = labels.argmax(dim=1).detach().cpu().numpy()\n",
    "               \n",
    "        preds.append(pred)\n",
    "        out_label_ids.append(out_label_id)\n",
    "\n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    result = {\"loss\": eval_loss}\n",
    "    \n",
    "    if args.multiclass:\n",
    "        tgts = torch.cat(out_label_ids, dim=0)\n",
    "        preds = torch.cat(preds, dim=0)\n",
    "\n",
    "        tgts_lbm = tgts[:, 0]\n",
    "        tgts_fys = tgts[:, 1]\n",
    "        tgts_onv = tgts[:, 2]\n",
    "        tgts_soc = tgts[:, 3]\n",
    "        tgts_vrz = tgts[:, 4]\n",
    "        tgts_won = tgts[:, 5]\n",
    "\n",
    "        preds_lbm = preds[:, 0]\n",
    "        preds_fys = preds[:, 1]\n",
    "        preds_onv = preds[:, 2]\n",
    "        preds_soc = preds[:, 3]\n",
    "        preds_vrz = preds[:, 4]\n",
    "        preds_won = preds[:, 5]        \n",
    "\n",
    "        result[\"rmse_6\"] = torch.sqrt(torch.mean((tgts - preds) ** 2))\n",
    "        mean_tgts = torch.mean(tgts)\n",
    "        ss_tot = torch.sum((tgts - mean_tgts) ** 2)\n",
    "        ss_res = torch.sum((tgts - preds) ** 2)\n",
    "        result[\"r_squared_6\"] = 1 - (ss_res / ss_tot)     \n",
    "\n",
    "        preds_np = preds.numpy().ravel()\n",
    "        tgts_np = tgts.numpy().ravel()\n",
    "        result[\"r_Pearson_6\"] = linregress(preds_np, tgts_np).rvalue\n",
    "\n",
    "        result[\"rmse_lbm\"] = torch.sqrt(torch.mean((tgts_lbm - preds_lbm) ** 2))\n",
    "        mean_tgts_lbm = torch.mean(tgts_lbm)\n",
    "        ss_tot_lbm = torch.sum((tgts_lbm - mean_tgts_lbm) ** 2)\n",
    "        ss_res_lbm = torch.sum((tgts_lbm - preds_lbm) ** 2)\n",
    "        result[\"r_squared_lbm\"] = 1 - (ss_res_lbm / ss_tot_lbm)\n",
    "        preds_lbm_np = preds_lbm.numpy().ravel()\n",
    "        tgts_lbm_np = tgts_lbm.numpy().ravel()\n",
    "        result[\"r_Pearson_lbm\"] = linregress(preds_lbm_np, tgts_lbm_np).rvalue\n",
    "\n",
    "        result[\"rmse_tgts_fys\"] = torch.sqrt(torch.mean((tgts_fys - preds_fys) ** 2))\n",
    "        mean_tgts_fys = torch.mean(tgts_fys)\n",
    "        ss_tot_fys = torch.sum((tgts_fys - mean_tgts_fys) ** 2)\n",
    "        ss_res_fys = torch.sum((tgts_fys - preds_fys) ** 2)\n",
    "        result[\"r_squared_fys\"] = 1 - (ss_res_fys / ss_tot_fys)\n",
    "        preds_fys_np = preds_fys.numpy().ravel()\n",
    "        tgts_fys_np = tgts_fys.numpy().ravel()\n",
    "        result[\"r_Pearson_fys\"] = linregress(preds_fys_np, tgts_fys_np).rvalue\n",
    "\n",
    "        result[\"rmse_tgts_onv\"] = torch.sqrt(torch.mean((tgts_onv - preds_onv) ** 2))\n",
    "        mean_tgts_onv = torch.mean(tgts_onv)\n",
    "        ss_tot_onv = torch.sum((tgts_onv - mean_tgts_onv) ** 2)\n",
    "        ss_res_onv = torch.sum((tgts_onv - preds_onv) ** 2)\n",
    "        result[\"r_squared_onv\"] = 1 - (ss_res_onv / ss_tot_onv)   \n",
    "        preds_onv_np = preds_onv.numpy().ravel()\n",
    "        tgts_onv_np = tgts_onv.numpy().ravel()        \n",
    "        result[\"r_Pearson_onv\"] = linregress(preds_onv_np, tgts_onv_np).rvalue\n",
    "\n",
    "        result[\"rmse_tgts_soc\"] = torch.sqrt(torch.mean((tgts_soc - preds_soc) ** 2))\n",
    "        mean_tgts_soc = torch.mean(tgts_soc)\n",
    "        ss_tot_soc = torch.sum((tgts_soc - mean_tgts_soc) ** 2)\n",
    "        ss_res_soc = torch.sum((tgts_soc - preds_soc) ** 2)\n",
    "        result[\"r_squared_soc\"] = 1 - (ss_res_soc / ss_tot_soc) \n",
    "        preds_soc_np = preds_soc.numpy().ravel()\n",
    "        tgts_soc_np = tgts_soc.numpy().ravel()        \n",
    "        result[\"r_Pearson_soc\"] = linregress(preds_soc_np, tgts_soc_np).rvalue\n",
    "\n",
    "        result[\"rmse_tgts_vrz\"] = torch.sqrt(torch.mean((tgts_vrz - preds_vrz) ** 2))\n",
    "        mean_tgts_vrz = torch.mean(tgts_vrz)\n",
    "        ss_tot_vrz = torch.sum((tgts_vrz - mean_tgts_vrz) ** 2)\n",
    "        ss_res_vrz = torch.sum((tgts_vrz - preds_vrz) ** 2)\n",
    "        result[\"r_squared_vrz\"] = 1 - (ss_res_vrz / ss_tot_vrz) \n",
    "        preds_vrz_np = preds_vrz.numpy().ravel()\n",
    "        tgts_vrz_np = tgts_vrz.numpy().ravel()          \n",
    "        result[\"r_Pearson_vrz\"] = linregress(preds_vrz_np, tgts_vrz_np).rvalue\n",
    "\n",
    "        result[\"rmse_tgts_won\"] = torch.sqrt(torch.mean((tgts_won - preds_won) ** 2))\n",
    "        mean_tgts_won = torch.mean(tgts_won)\n",
    "        ss_tot_won = torch.sum((tgts_won - mean_tgts_won) ** 2)\n",
    "        ss_res_won = torch.sum((tgts_won - preds_won) ** 2)\n",
    "        result[\"r_squared_won\"] = 1 - (ss_res_won / ss_tot_won)\n",
    "        preds_won_np = preds_won.numpy().ravel()\n",
    "        tgts_won_np = tgts_won.numpy().ravel()  \n",
    "        result[\"r_Pearson_won\"] = linregress(preds_won_np, tgts_won_np).rvalue\n",
    "\n",
    "        if test:\n",
    "            # Extract ground truth and predicted values for plotting\n",
    "            tgts_lbm_plot = tgts[:, 0].numpy()\n",
    "            tgts_fys_plot = tgts[:, 1].numpy()\n",
    "            tgts_onv_plot = tgts[:, 2].numpy()\n",
    "            tgts_soc_plot = tgts[:, 3].numpy()\n",
    "            tgts_vrz_plot = tgts[:, 4].numpy()\n",
    "            tgts_won_plot = tgts[:, 5].numpy()\n",
    "    \n",
    "            preds_lbm_plot = preds[:, 0].numpy()\n",
    "            preds_fys_plot = preds[:, 1].numpy()\n",
    "            preds_onv_plot = preds[:, 2].numpy()\n",
    "            preds_soc_plot = preds[:, 3].numpy()\n",
    "            preds_vrz_plot = preds[:, 4].numpy()\n",
    "            preds_won_plot = preds[:, 5].numpy()\n",
    "    \n",
    "            # Create chart\n",
    "            import matplotlib.pyplot as plt\n",
    "            fig, axes = plt.subplots(3, 2, figsize=(15, 15))\n",
    "            plot_density_scatter(tgts_lbm_plot, preds_lbm_plot, \"Livability\", axes[0, 0], xlim=(3.4, 4.6), ylim=(3.4, 4.6))\n",
    "            plot_density_scatter(tgts_fys_plot, preds_fys_plot, \"Phy\", axes[0, 1], xlim=(-0.3, 0.2), ylim=(-0.3, 0.2))\n",
    "            plot_density_scatter(tgts_onv_plot, preds_onv_plot, \"Nui\", axes[1, 0], xlim=(-0.5, 0.2), ylim=(-0.5, 0.2))\n",
    "            plot_density_scatter(tgts_soc_plot, preds_soc_plot, \"Soc\", axes[1, 1], xlim=(-0.1, 0.35), ylim=(-0.1, 0.35))\n",
    "            plot_density_scatter(tgts_vrz_plot, preds_vrz_plot, \"Ame\", axes[2, 0], xlim=(-0.2, 0.4), ylim=(-0.2, 0.4))\n",
    "            plot_density_scatter(tgts_won_plot, preds_won_plot, \"Hou\", axes[2, 1], xlim=(-0.3, 0.4), ylim=(-0.3, 0.4))\n",
    "    \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "           \n",
    "    else:\n",
    "        preds = [l for sl in preds for l in sl]\n",
    "        out_label_ids = [l for sl in out_label_ids for l in sl]\n",
    "        result[\"micro_f1\"] = f1_score(out_label_ids, preds, average=\"micro\")\n",
    "        result[\"macro_f1\"] = f1_score(out_label_ids, preds, average=\"macro\")\n",
    "\n",
    "    output_eval_file = os.path.join(eval_output_dir, prefix, \"eval_results.txt\")\n",
    "    if not os.path.exists(os.path.dirname(output_eval_file)):\n",
    "        os.makedirs(os.path.dirname(output_eval_file))\n",
    "    with open(output_eval_file, \"a\") as writer:\n",
    "        logger.info(f\"***** Eval results {prefix} *****\")\n",
    "        for key in sorted(result.keys()):\n",
    "            logger.info(f\"  {key} = {str(result[key])}\")\n",
    "            writer.write(f\"{key} = {str(result[key])}\\n\")\n",
    "            if test:\n",
    "                tb_writer.add_scalar(f\"eval_{key}\", result[key], nb_eval_steps)\n",
    "    \n",
    "    if test:\n",
    "        tb_writer.close()\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mrKUcxxcbs3"
   },
   "source": [
    "## Training MMBT Model \n",
    "\n",
    "Set up logging and the MMBT Model. Similar to the text-only model, check points \n",
    "are saved during a similar customizable interval.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1678711259831,
     "user": {
      "displayName": "Sui Mai",
      "userId": "09591388850972871883"
     },
     "user_tz": -60
    },
    "id": "-3-ZxIuRcdfO",
    "outputId": "0d5ccc72-5818-43eb-aa17-c710422835ad"
   },
   "outputs": [],
   "source": [
    "# Resolve output_dir relative to current directory (use relative paths)\n",
    "current_dir = os.getcwd()\n",
    "print(f\"ðŸ“ Current working directory: {current_dir}\")\n",
    "",
    "# Resolve output_dir - keep it relative if possible\n",
    "if os.path.isabs(args.output_dir):\n",
    "    # If absolute path provided, try to convert to relative\n",
    "    try:\n",
    "        rel_path = os.path.relpath(args.output_dir, current_dir)\n",
    "        if not rel_path.startswith('..'):\n",
    "            # Can be made relative, use it\n",
    "            args.output_dir = rel_path\n",
    "            print(f\"ðŸ“‚ Converted absolute path to relative: {args.output_dir}\")\n",
    "        else:\n",
    "            # Keep absolute path but normalize\n",
    "            args.output_dir = os.path.normpath(args.output_dir)\n",
    "            print(f\"ðŸ“‚ Using absolute path: {args.output_dir}\")\n",
    "    except ValueError:\n",
    "        # Can't convert (different drives on Windows), keep absolute\n",
    "        args.output_dir = os.path.normpath(args.output_dir)\n",
    "        print(f\"ðŸ“‚ Using absolute path: {args.output_dir}\")\n",
    "else:\n",
    "    # Already relative, normalize it\n",
    "    args.output_dir = os.path.normpath(args.output_dir)\n",
    "    print(f\"ðŸ“‚ Using relative path: {args.output_dir}\")\n",
    "",
    "# Resolve full path for creating directories\n",
    "output_dir_full = os.path.join(current_dir, args.output_dir) if not os.path.isabs(args.output_dir) else args.output_dir\n",
    "output_dir_full = os.path.normpath(output_dir_full)\n",
    "",
    "print(f\"ðŸ“‚ Resolved output_dir (full path): {output_dir_full}\")\n",
    "",
    "# Create output directory if it doesn't exist\n",
    "if not os.path.exists(output_dir_full):\n",
    "    os.makedirs(output_dir_full)\n",
    "    print(f\"ðŸ“ Created output directory: {output_dir_full}\")\n",
    "",
    "# Update args.output_dir to use the full path for file operations\n",
    "args.output_dir = output_dir_full\n",
    "",
    "# Set up logging\n",
    "file_handler = logging.FileHandler(os.path.join(args.output_dir, \"training_log.txt\"))\n",
    "",
    "# Set up logger\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "",
    "# Add file handler if not already added\n",
    "if not logger.handlers:\n",
    "    file_handler.setLevel(logging.INFO)\n",
    "    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "    file_handler.setFormatter(formatter)\n",
    "    logger.addHandler(file_handler)\n",
    "    \n",
    "    # Also add console handler\n",
    "    console_handler = logging.StreamHandler()\n",
    "    console_handler.setLevel(logging.INFO)\n",
    "    console_handler.setFormatter(formatter)\n",
    "    logger.addHandler(console_handler)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124,
     "referenced_widgets": [
      "7879dd9f4df5432386363953e0bd6788",
      "ab34b6088b8c4a81a81585e92ef00200",
      "2db903bb0785468cbc26dc697bbfdf4b",
      "a5abd70b29364b0ca28814269f306100",
      "8eb9fe421d6d4cc5a8336c546699cf3c",
      "1405e19df3f24853ad609e2dbeb32216",
      "bed578b004684f649250ed21aaf66a2e",
      "cc45c12d9f654f9e92fcf1589e67dd48",
      "2aed0729d4a34d68bef46f0f643fe9a4",
      "303cbc0b0e524262b47ec5bec585d855",
      "29ce950be8aa4ad6999f243064f3270b"
     ]
    },
    "executionInfo": {
     "elapsed": 20977,
     "status": "ok",
     "timestamp": 1678711280789,
     "user": {
      "displayName": "Sui Mai",
      "userId": "09591388850972871883"
     },
     "user_tz": -60
    },
    "id": "ZDgzsLlcc-Uk",
    "outputId": "756394a6-7638-4a4b-a0e4-30fb57c9ee42"
   },
   "outputs": [],
   "source": [
    "# Setup model\n",
    "if args.multiclass:\n",
    "    labels = get_multiclass_labels()\n",
    "    num_labels = len(labels)\n",
    "else:\n",
    "    labels = get_labels()\n",
    "    num_labels = len(labels)\n",
    "transformer_config = AutoConfig.from_pretrained(args.config_name if args.config_name else args.model_name, num_labels=num_labels)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "        args.tokenizer_name if args.tokenizer_name else args.model_name,\n",
    "        do_lower_case=True,\n",
    "        cache_dir=None,\n",
    "    )\n",
    "transformer = AutoModel.from_pretrained(args.model_name, config=transformer_config, cache_dir=None)\n",
    "img_encoder = ImageEncoderDenseNet(num_image_embeds=args.num_image_embeds)\n",
    "multimodal_config = MMBTConfig(transformer, img_encoder, num_labels=num_labels, modal_hidden_size=1024)\n",
    "model = MMBTForClassification(transformer_config, multimodal_config)\n",
    "\n",
    "model.to(args.device)\n",
    "\n",
    "logger.info(f\"Training/evaluation parameters: {args}\")\n",
    "\n",
    "# Training\n",
    "if args.do_train:\n",
    "\n",
    "   \n",
    "    train_dataset = load_examples(tokenizer, args)\n",
    "    # criterion = nn.CrossEntropyLoss\n",
    "    global_step, tr_loss = train(args, train_dataset, model, tokenizer)\n",
    "    logger.info(\" global_step = %s, average loss = %s\", global_step, tr_loss)\n",
    "\n",
    "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
    "    logger.info(\"Saving model checkpoint to %s\", args.output_dir)\n",
    "    # Save a trained model, confitopguration and tokenizer using `save_pretrained()`.\n",
    "    # They can then be reloaded using `from_pretrained()\n",
    "    model_to_save = (model.module if hasattr(model, \"module\") else model)  # Take care of distributed/parallel training\n",
    "    torch.save(model_to_save.state_dict(), os.path.join(args.output_dir, WEIGHTS_NAME))\n",
    "    tokenizer.save_pretrained(args.output_dir)\n",
    "    transformer_config.save_pretrained(args.output_dir)\n",
    "    # Good practice: save your training arguments together with the trained model\n",
    "    torch.save(args, os.path.join(args.output_dir, \"training_args.bin\"))\n",
    "\n",
    "    # Load a trained model and vocabulary that you have fine-tuned\n",
    "    model = MMBTForClassification(transformer_config, multimodal_config)\n",
    "    model.load_state_dict(torch.load(os.path.join(args.output_dir, WEIGHTS_NAME)))\n",
    "    tokenizer = AutoTokenizer.from_pretrained(args.output_dir)\n",
    "    model.to(args.device)\n",
    "logger.info(\"***** Training Finished *****\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Se45Ve33_KAr"
   },
   "source": [
    "## Evaluating on the Test Set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2677050,
     "status": "ok",
     "timestamp": 1678713957824,
     "user": {
      "displayName": "Sui Mai",
      "userId": "09591388850972871883"
     },
     "user_tz": -60
    },
    "id": "vo2zxNJDYbmh",
    "outputId": "b3086233-6d82-41f6-efa6-d2460cd64915"
   },
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "results = {}\n",
    "print(\"=== Start Model Evaluation ===\")\n",
    "print(f\"do_eval = {args.do_eval}\")\n",
    "if args.do_eval:\n",
    "    # Use relative paths - work from current directory\n",
    "    current_dir = os.getcwd()\n",
    "    print(f\"ðŸ“ Current working directory: {current_dir}\")\n",
    "    \n",
    "    # Resolve output_dir - keep it relative if possible\n",
    "    if os.path.isabs(args.output_dir):\n",
    "        # If absolute path provided, try to convert to relative\n",
    "        try:\n",
    "            rel_path = os.path.relpath(args.output_dir, current_dir)\n",
    "            if not rel_path.startswith('..'):\n",
    "                # Can be made relative, use it\n",
    "                output_dir_path = os.path.join(current_dir, rel_path)\n",
    "                print(f\"ðŸ“‚ Converted absolute path to relative: {rel_path}\")\n",
    "            else:\n",
    "                # Keep absolute path\n",
    "                output_dir_path = args.output_dir\n",
    "                print(f\"ðŸ“‚ Using absolute path: {output_dir_path}\")\n",
    "        except ValueError:\n",
    "            # Can't convert (different drives on Windows), keep absolute\n",
    "            output_dir_path = args.output_dir\n",
    "            print(f\"ðŸ“‚ Using absolute path: {output_dir_path}\")\n",
    "    else:\n",
    "        # Already relative, resolve from current directory\n",
    "        output_dir_path = os.path.join(current_dir, args.output_dir)\n",
    "        print(f\"ðŸ“‚ Using relative path: {args.output_dir} -> {output_dir_path}\")\n",
    "    \n",
    "    # Normalize the path (resolve .. and .)\n",
    "    output_dir_path = os.path.normpath(output_dir_path)\n",
    "    \n",
    "    print(f\"ðŸ“‚ Resolved output_dir: {output_dir_path}\")\n",
    "    print(f\"ðŸ“‚ output_dir exists: {os.path.exists(output_dir_path)}\")\n",
    "    \n",
    "    # Use resolved path for checkpoints\n",
    "    checkpoints = []\n",
    "    \n",
    "    # Check if root output_dir has pytorch_model.bin\n",
    "    root_model_path = os.path.join(output_dir_path, 'pytorch_model.bin')\n",
    "    if os.path.exists(root_model_path):\n",
    "        checkpoints.append(output_dir_path)\n",
    "        print(f\"âœ… Found root model: {output_dir_path}\")\n",
    "    \n",
    "    if args.eval_all_checkpoints:\n",
    "        # Search for folders containing \"checkpoint\" keyword\n",
    "        checkpoint_dirs = []\n",
    "        if os.path.exists(output_dir_path):\n",
    "            for item in os.listdir(output_dir_path):\n",
    "                item_path = os.path.join(output_dir_path, item)\n",
    "                if os.path.isdir(item_path) and \"checkpoint\" in item:\n",
    "                    # Check if pytorch_model.bin exists in the directory\n",
    "                    model_file = os.path.join(item_path, \"pytorch_model.bin\")\n",
    "                    if os.path.exists(model_file):\n",
    "                        checkpoint_dirs.append(item_path)\n",
    "        \n",
    "        if checkpoint_dirs:\n",
    "            checkpoints.extend(sorted(checkpoint_dirs))\n",
    "            print(f\"âœ… Found checkpoint folders: {checkpoint_dirs}\")\n",
    "        else:\n",
    "            print(f\"âš ï¸  No checkpoint folders found in: {output_dir_path}\")\n",
    "    \n",
    "    # If no checkpoints found at all, still try to use output_dir\n",
    "    if not checkpoints:\n",
    "        checkpoints = [output_dir_path]\n",
    "        print(f\"âš ï¸  No models found, will try: {output_dir_path}\")\n",
    "\n",
    "    logger.info(\"Evaluate the following checkpoints: %s\", checkpoints)\n",
    "    print(f\"Found {len(checkpoints)} checkpoints: {checkpoints}\")\n",
    "\n",
    "    for checkpoint in checkpoints:\n",
    "        global_step = checkpoint.split(\"-\")[-1] if len(checkpoints) > 1 else \"\"\n",
    "        print (\"global_step\",global_step)        \n",
    "        prefix = checkpoint.split(\"/\")[-1] if checkpoint.find(\"checkpoint\") != -1 else \"\"\n",
    "        print(f\"Loading model: {checkpoint}\")\n",
    "        model = MMBTForClassification(transformer_config, multimodal_config)\n",
    "        model_path = os.path.join(checkpoint, 'pytorch_model.bin')\n",
    "        print(f\"Loading model file: {model_path}\")\n",
    "        \n",
    "        # Check if file exists before loading\n",
    "        if not os.path.exists(model_path):\n",
    "            print(f\"âŒ Model file not found: {model_path}\")\n",
    "            print(f\"   Please ensure the model is trained and saved in: {checkpoint}\")\n",
    "            print(f\"   Current working directory: {current_dir}\")\n",
    "            print(f\"   You may need to:\")\n",
    "            print(f\"     1. Train the model first, or\")\n",
    "            print(f\"     2. Download the model to: {checkpoint}\")\n",
    "            continue\n",
    "        \n",
    "        # Load state_dict and handle compatibility issues\n",
    "        state_dict = torch.load(model_path)\n",
    "        \n",
    "        # Remove keys that may cause compatibility issues\n",
    "        keys_to_remove = []\n",
    "        problematic_patterns = ['position_ids', 'token_type_ids']\n",
    "        \n",
    "        for key in state_dict.keys():\n",
    "            for pattern in problematic_patterns:\n",
    "                if pattern in key and 'embeddings' in key:\n",
    "                    keys_to_remove.append(key)\n",
    "                    break\n",
    "        \n",
    "        if keys_to_remove:\n",
    "            print(f\"ðŸ”§ Removed {len(keys_to_remove)} incompatible keys:\")\n",
    "            for key in keys_to_remove:\n",
    "                print(f\"   - {key}\")\n",
    "                del state_dict[key]\n",
    "        \n",
    "        # Use strict=False to allow partial matching\n",
    "        missing_keys, unexpected_keys = model.load_state_dict(state_dict, strict=False)\n",
    "        \n",
    "        if missing_keys:\n",
    "            print(f\"âš ï¸  Missing keys: {len(missing_keys)} \")\n",
    "        if unexpected_keys:\n",
    "            print(f\"âš ï¸  Unexpected keys: {len(unexpected_keys)} \")\n",
    "        \n",
    "        print(\"âœ… Model loaded\")\n",
    "        model.to(args.device)\n",
    "        print(\"Starting evaluation...\")\n",
    "        result = evaluate(args, model, tokenizer, evaluate=True, test=True, prefix=prefix)\n",
    "        print(f\"Evaluation complete,Number of results: {len(result)}\")\n",
    "        result = dict((k + \"_{}\".format(global_step), v) for k, v in result.items())\n",
    "        results.update(result)\n",
    "\n",
    "results.keys()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1678713957825,
     "user": {
      "displayName": "Sui Mai",
      "userId": "09591388850972871883"
     },
     "user_tz": -60
    },
    "id": "mu5ge_8Yjg6w",
    "outputId": "0fd8cfdf-36d0-4f9b-ea9f-7c78ff166fa5"
   },
   "outputs": [],
   "source": [
    "print(\"=== Evaluation results ===\")\n",
    "print(f\"Number of results: {len(results)}\")\n",
    "if results:\n",
    "    print(\"Result details:\")\n",
    "    for key, value in results.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "else:\n",
    "    print(\"NoFoundEvaluation resultsï¼\")\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fMeqM4JD_bbV"
   },
   "source": [
    "## Saving Test Eval Results\n",
    "\n",
    "The code automatically saved evaluation result from each checkpoint in its respective folder. This next cell simply saves all of them in one place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 350,
     "status": "ok",
     "timestamp": 1678713958164,
     "user": {
      "displayName": "Sui Mai",
      "userId": "09591388850972871883"
     },
     "user_tz": -60
    },
    "id": "BvH1zD7si_rg"
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(args.output_dir, \"final_eval_results.txt\"), mode='a', encoding='utf-8') as out_f:\n",
    "    print(results, file=out_f)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python (py39)",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0d9117147b0a413c98cd76112c67b3a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ce4dc208e7794b99b001d63adc03f196",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_91a737e1134544afa343640f1cb7a5ca",
      "value": "Downloading (â€¦)okenizer_config.json: 100%"
     }
    },
    "0ff36347a90a42e4a705f91d07f99324": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1405e19df3f24853ad609e2dbeb32216": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "21a7ceb4d8384c4fb75fa6cfa979824b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_269e9c6d072842f998af2e3cc55ebada",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_400f1ce98b894d1c8f3bdd32c08377a7",
      "value": " 625/625 [00:00&lt;00:00, 25.0kB/s]"
     }
    },
    "22e78ff34aa5401d93f2b6afeeef36a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7867862f9b354bbc9b84a2977ae6eff8",
      "max": 625,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_31c54a05d50140b192a0fdf56d647694",
      "value": 625
     }
    },
    "269e9c6d072842f998af2e3cc55ebada": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "270e4d4761f944d083e45af13ff50ee2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "29ce950be8aa4ad6999f243064f3270b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2aed0729d4a34d68bef46f0f643fe9a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2db903bb0785468cbc26dc697bbfdf4b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cc45c12d9f654f9e92fcf1589e67dd48",
      "max": 672271273,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2aed0729d4a34d68bef46f0f643fe9a4",
      "value": 672271273
     }
    },
    "303cbc0b0e524262b47ec5bec585d855": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "31c54a05d50140b192a0fdf56d647694": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "34ed8ad093ec4a3cbeff7454279a11d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3e68b4254b8a41249797f99cab88d4f3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "400f1ce98b894d1c8f3bdd32c08377a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "44ed7fe967414a3db9ecda413660f2d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6c97deab4fee41f592167ddce3223c0e",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_bde88ca9771c44f285664c5fe74222c7",
      "value": "Downloading (â€¦)solve/main/vocab.txt: 100%"
     }
    },
    "5081b02dc8de435e9033c7dcb82b0962": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f74d8d4596b4472fbda6663375565e59",
      "max": 1715180,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b9c1593889fb4795bb58e8f798408235",
      "value": 1715180
     }
    },
    "6c97deab4fee41f592167ddce3223c0e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "72ed8b9958614dfda0b3d3bdf6d71378": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "747bc2afec7a4f4d9c0bea4e8498e0cd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7867862f9b354bbc9b84a2977ae6eff8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7879dd9f4df5432386363953e0bd6788": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ab34b6088b8c4a81a81585e92ef00200",
       "IPY_MODEL_2db903bb0785468cbc26dc697bbfdf4b",
       "IPY_MODEL_a5abd70b29364b0ca28814269f306100"
      ],
      "layout": "IPY_MODEL_8eb9fe421d6d4cc5a8336c546699cf3c"
     }
    },
    "7b67bc5234ef46c496738e9acb1edb20": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7f1f8393330f459ba14e11d4bc5cbb07": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fa4126b6651c411fa63fb800b9478c95",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_34ed8ad093ec4a3cbeff7454279a11d8",
      "value": " 872k/872k [00:00&lt;00:00, 2.82MB/s]"
     }
    },
    "80574460226a475d977299562fbed072": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "84df966af26b4850812e4b84a7c2baaa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "85591e73ae574650916daf40a877326c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b3a612e6191a496dbff4d55cee76af73",
       "IPY_MODEL_22e78ff34aa5401d93f2b6afeeef36a7",
       "IPY_MODEL_21a7ceb4d8384c4fb75fa6cfa979824b"
      ],
      "layout": "IPY_MODEL_97ace72d1e274732ab8ab5b7e762b5e3"
     }
    },
    "85e5c7f55dac42dea724729db70e01fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3e68b4254b8a41249797f99cab88d4f3",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_7b67bc5234ef46c496738e9acb1edb20",
      "value": " 28.0/28.0 [00:00&lt;00:00, 879B/s]"
     }
    },
    "894ce7267bde4252a68e4f538de90b86": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0d9117147b0a413c98cd76112c67b3a6",
       "IPY_MODEL_c743a9299c784dbf91fb209e30de9c7c",
       "IPY_MODEL_85e5c7f55dac42dea724729db70e01fa"
      ],
      "layout": "IPY_MODEL_a3f564f3b8cf4be1988863320a4682ea"
     }
    },
    "8b2c9d0a6d72481b96ee7d7cf3d79d03": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8eb9fe421d6d4cc5a8336c546699cf3c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8ec5350d0c984b75a128e79472c5a10f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "91a737e1134544afa343640f1cb7a5ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "970ff7dc97234313ab994ab80152fdff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "97ace72d1e274732ab8ab5b7e762b5e3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a3f564f3b8cf4be1988863320a4682ea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a5abd70b29364b0ca28814269f306100": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_303cbc0b0e524262b47ec5bec585d855",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_29ce950be8aa4ad6999f243064f3270b",
      "value": " 672M/672M [00:09&lt;00:00, 75.8MB/s]"
     }
    },
    "ab34b6088b8c4a81a81585e92ef00200": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1405e19df3f24853ad609e2dbeb32216",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_bed578b004684f649250ed21aaf66a2e",
      "value": "Downloading pytorch_model.bin: 100%"
     }
    },
    "b31b075eaf1844aaa45b534425b5b2a7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b3a612e6191a496dbff4d55cee76af73": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_747bc2afec7a4f4d9c0bea4e8498e0cd",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_c65b23c4d46747c7b0d9968348ec15fc",
      "value": "Downloading (â€¦)lve/main/config.json: 100%"
     }
    },
    "b9c1593889fb4795bb58e8f798408235": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bde88ca9771c44f285664c5fe74222c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bed578b004684f649250ed21aaf66a2e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c65b23c4d46747c7b0d9968348ec15fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c743a9299c784dbf91fb209e30de9c7c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_80574460226a475d977299562fbed072",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_72ed8b9958614dfda0b3d3bdf6d71378",
      "value": 28
     }
    },
    "cbdce03e88604e97881fcf5a9e6bbc33": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b31b075eaf1844aaa45b534425b5b2a7",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_84df966af26b4850812e4b84a7c2baaa",
      "value": "Downloading (â€¦)/main/tokenizer.json: 100%"
     }
    },
    "cc45c12d9f654f9e92fcf1589e67dd48": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ce4dc208e7794b99b001d63adc03f196": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ceac6d587533457cb9d2eed0a1ebdba8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_44ed7fe967414a3db9ecda413660f2d6",
       "IPY_MODEL_f95c21c708fa4923a8b49fb8209c39a2",
       "IPY_MODEL_7f1f8393330f459ba14e11d4bc5cbb07"
      ],
      "layout": "IPY_MODEL_970ff7dc97234313ab994ab80152fdff"
     }
    },
    "dd69a4af9fdb46f484f1873101cdc1ff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e5622b66d7c14a49bd6d8f45b2ce5afc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cbdce03e88604e97881fcf5a9e6bbc33",
       "IPY_MODEL_5081b02dc8de435e9033c7dcb82b0962",
       "IPY_MODEL_f825f26d6a6e47f0b5d6371f5177bcd5"
      ],
      "layout": "IPY_MODEL_dd69a4af9fdb46f484f1873101cdc1ff"
     }
    },
    "f74d8d4596b4472fbda6663375565e59": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f825f26d6a6e47f0b5d6371f5177bcd5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8b2c9d0a6d72481b96ee7d7cf3d79d03",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_270e4d4761f944d083e45af13ff50ee2",
      "value": " 1.72M/1.72M [00:00&lt;00:00, 4.62MB/s]"
     }
    },
    "f95c21c708fa4923a8b49fb8209c39a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8ec5350d0c984b75a128e79472c5a10f",
      "max": 871891,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0ff36347a90a42e4a705f91d07f99324",
      "value": 871891
     }
    },
    "fa4126b6651c411fa63fb800b9478c95": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}